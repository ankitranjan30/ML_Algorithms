{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy.random import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape =  (120, 4) df_train_y.shape =  (120, 1)\n",
      "df_test.shape =  (30, 4) df_test_y.shape =  (30, 1)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn import datasets\n",
    "#iris = datasets.load_iris() \n",
    "#print(iris)\n",
    "  \n",
    "iris_df = pd.read_csv(\"C:/Users/ankit/Desktop/iris.data\",header=None) # , columns=['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width'] \n",
    "np.random.seed(42)\n",
    "\n",
    "iris_df.columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Target']\n",
    "\n",
    "# iris_df['Target'].replace('Iris-setosa', [0], inplace=True) \n",
    "# iris_df['Target'].replace('Iris-vercicolor',[1], inplace=True) \n",
    "# iris_df['Target'].replace('Iris-virginica',[2], inplace=True)\n",
    "\n",
    "iris_df['Target'] = np.where(iris_df['Target'] == 'Iris-setosa', 0.0, iris_df['Target'])\n",
    "iris_df['Target'] = np.where(iris_df['Target'] == 'Iris-versicolor', 1.0, iris_df['Target'])\n",
    "iris_df['Target'] = np.where(iris_df['Target'] == 'Iris-virginica', 2.0, iris_df['Target'])\n",
    "\n",
    "#iris_df.Target[iris_df.Target == 'Iris-setosa'] = 0.0\n",
    "#iris_df.Target[iris_df.Target == 'Iris-versicolor'] = 1.0\n",
    "#iris_df.Target[iris_df.Target == 'Iris-virginica'] = 2.0\n",
    "\n",
    "#iris_df = iris_df[['']] \n",
    "#iris_df['Target'] = iris.target \n",
    "#iris_df['Target'].value_counts()\n",
    "#iris_df = iris_df[iris_df.Target != 2]\n",
    "#iris_df['Target'].value_counts()\n",
    "df = iris_df\n",
    "df = np.array(df) \n",
    "np.random.shuffle( df)\n",
    "\n",
    "eightypercent = int(0.8 * len(df))\n",
    "twentypercent = int(0.2 * len(df))\n",
    "_ ,features = df.shape\n",
    "features = features - 1\n",
    "\n",
    "df_train = df[:eightypercent,:features].reshape(eightypercent, features)\n",
    "df_train_y = df[:eightypercent,-1].reshape(eightypercent, 1)\n",
    "\n",
    "df_test = df[:twentypercent,:features].reshape(twentypercent,features)\n",
    "df_test_y = df[:twentypercent,-1].reshape(twentypercent,1)\n",
    "\n",
    "print(\"df_train.shape = \",df_train.shape,\"df_train_y.shape = \",df_train_y.shape)\n",
    "print(\"df_test.shape = \",df_test.shape,\"df_test_y.shape = \",df_test_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg:\n",
    "\n",
    "    def fit(self, X, y_class):\n",
    "        # Least Squares\n",
    "        N_instances, N_features = X.shape\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "        #print(X)       \n",
    "        self.weights = np.zeros(X.shape[1]).reshape(X.shape[1], 1) # 3 weights now not 2\n",
    "        self.weights = np.dot(np.linalg.inv(np.dot(np.transpose(X), X)), np.dot(np.transpose(X), y_class))\n",
    "        self.weights = self.weights.reshape(len(self.weights), 1)\n",
    "        print(\"weights.shape = \",self.weights.shape)\n",
    "        \n",
    "        #print(\"self.weights\", (self.weights).shape)\n",
    "        #print(\"N_instances = \",N_instances,\"N_features\",N_features)\n",
    "        \n",
    "        return self.weights\n",
    "        #print(o_class.shape)\n",
    "            \n",
    "    def prediction(self, X): #for training and testing data both we want to predict\n",
    "        N_instances, N_features = X.shape\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))        \n",
    "        \n",
    "        #net = np.array(np.dot(X,self.weights)) #+ self.bias\n",
    "        #np.array(net)\n",
    "        #print((net))\n",
    "        #print(\"net shape\",net.shape)\n",
    "        y = np.dot(X, self.weights)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        y = [1 if (i >= 0.5 and i < 1.5) else 0 if (i< 0.5 and i >=  -0.5) else 2 for i in y]\n",
    "        y = np.array(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_actual):\n",
    "    count = 0\n",
    "    for i in range(len(y_actual)):\n",
    "        if(y_pred[i] == y_actual[i]):\n",
    "            count += 1\n",
    "    accuracy = 100* ((count / len(y_actual)))\n",
    "    print(\"accuracy = \", accuracy,\"\\n -----\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k values from 2 to 10  =  [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "valid_k_values divisible by len(dataset)=  [ 2  3  5  6 10]\n",
      "train_percent =  [ 75 100 120 125 135]\n",
      "test_percent =  [75 50 30 25 15]\n",
      "k = 2 \n",
      "\n",
      "df_train.shape =  (75, 4) df_train_y.shape =  (75, 1)\n",
      "df_test.shape =  (75, 4) df_test_y.shape =  (75, 1)\n",
      "weights.shape =  (5, 1)\n",
      "(75, 1)\n",
      "accuracy =  98.66666666666667 \n",
      " -----\n",
      "k = 3 \n",
      "\n",
      "df_train.shape =  (100, 4) df_train_y.shape =  (100, 1)\n",
      "df_test.shape =  (50, 4) df_test_y.shape =  (50, 1)\n",
      "weights.shape =  (5, 1)\n",
      "(50, 1)\n",
      "accuracy =  98.0 \n",
      " -----\n",
      "k = 5 \n",
      "\n",
      "df_train.shape =  (120, 4) df_train_y.shape =  (120, 1)\n",
      "df_test.shape =  (30, 4) df_test_y.shape =  (30, 1)\n",
      "weights.shape =  (5, 1)\n",
      "(30, 1)\n",
      "accuracy =  100.0 \n",
      " -----\n",
      "k = 6 \n",
      "\n",
      "df_train.shape =  (125, 4) df_train_y.shape =  (125, 1)\n",
      "df_test.shape =  (25, 4) df_test_y.shape =  (25, 1)\n",
      "weights.shape =  (5, 1)\n",
      "(25, 1)\n",
      "accuracy =  100.0 \n",
      " -----\n",
      "k = 10 \n",
      "\n",
      "df_train.shape =  (135, 4) df_train_y.shape =  (135, 1)\n",
      "df_test.shape =  (15, 4) df_test_y.shape =  (15, 1)\n",
      "weights.shape =  (5, 1)\n",
      "(15, 1)\n",
      "accuracy =  100.0 \n",
      " -----\n",
      "max(accuracies) =  100.0 index of max accuracy =  2\n",
      "max accuracy's corresponding k-value =  5\n"
     ]
    }
   ],
   "source": [
    "## K- fold cross validation\n",
    "\n",
    "k_two_to_ten = [i for i in range(2,11)]\n",
    "print(\"k values from 2 to 10  = \",k_two_to_ten)\n",
    " \n",
    "valid_k_values = list(filter(lambda k: len(df)%k == 0, k_two_to_ten)) \n",
    "print(\"valid_k_values divisible by len(dataset)= \",np.array(valid_k_values))\n",
    "\n",
    "valid_k_values_list = []\n",
    "for i in range(len(valid_k_values)):\n",
    "    valid_k_values_list.append(int(valid_k_values[i]))  \n",
    "\n",
    "\n",
    "valid_k_values = np.array(valid_k_values_list)\n",
    "\n",
    "train_percent = ( ((valid_k_values - 1)/valid_k_values) * len(df))\n",
    "test_percent = ( (1/valid_k_values) * len(df))\n",
    "train_percent = train_percent.astype('int32')\n",
    "test_percent = test_percent.astype('int32')\n",
    "print(\"train_percent = \",train_percent)\n",
    "print(\"test_percent = \",test_percent)\n",
    "\n",
    "_ ,features = df.shape\n",
    "features = features - 1\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for i in valid_k_values:\n",
    "    \n",
    "    print(\"k =\",i,\"\\n\")\n",
    "    train_percent = ( ((i - 1)/i) * len(df))\n",
    "    test_percent = ( (1/i) * len(df))\n",
    "    train_percent = train_percent.astype('int32')\n",
    "    test_percent = test_percent.astype('int32')\n",
    "\n",
    "    df_train = df[:train_percent,:features].reshape(train_percent, features)\n",
    "    df_train_y = df[:train_percent,-1].reshape(train_percent, 1)\n",
    "\n",
    "    df_test = df[:test_percent,:features].reshape(test_percent,features)\n",
    "    df_test_y = df[:test_percent,-1].reshape(test_percent,1)\n",
    "\n",
    "    print(\"df_train.shape = \",df_train.shape,\"df_train_y.shape = \",df_train_y.shape)\n",
    "    print(\"df_test.shape = \",df_test.shape,\"df_test_y.shape = \",df_test_y.shape)\n",
    "\n",
    "    X_LinearReg =  LinearReg() \n",
    "\n",
    "    #print(\"X_train =\",X_train)\n",
    "    X_LinearReg.fit(df_train.astype(np.float64), df_train_y.astype(np.float64))\n",
    "\n",
    "    #print(\"X_train =\",X_train)\n",
    "    PRED_CLASS_Test = X_LinearReg.prediction(df_test)\n",
    "    #print(PRED_CLASS_Test)\n",
    "    print(PRED_CLASS_Test.reshape(test_percent,1).shape)\n",
    "    #print(\"For Test set:\\n\")\n",
    "\n",
    "    acc = accuracy(PRED_CLASS_Test, df_test_y)\n",
    "\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "\n",
    "max_accuracy = max(accuracies)\n",
    "index_max_accuracy = accuracies.index(max(accuracies))\n",
    "print(\"max(accuracies) = \",max_accuracy,\"index of max accuracy = \" ,index_max_accuracy)\n",
    "print(\"max accuracy's corresponding k-value = \", valid_k_values[index_max_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT DESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearReg_Gradient_Descent:\n",
    "    def __init__(self, LearningRate = 0.01, iterations = 10000):\n",
    "        self.eta_lr = LearningRate\n",
    "        self.total_iterations = iterations\n",
    "        \n",
    "        self.weights = weights\n",
    "        #self.bias = bias\n",
    "    \n",
    "    \n",
    "    def fit(self,X,y_class_groundtruth): #only for training data\n",
    "        # Gradient Descent\n",
    "        N_instances, N_features = X.shape\n",
    "\n",
    "        \n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "        #print(X)       \n",
    "        self.weights = np.zeros(X.shape[1]).reshape(X.shape[1], 1) # 3 weights now not 2\n",
    "        #self.weights = np.dot(np.linalg.inv(np.dot(np.transpose(X), X)), np.dot(np.transpose(X), y_class))\n",
    "        self.weights = self.weights.reshape(len(self.weights), 1)\n",
    "        print(\"weights.shape = \",self.weights.shape)        \n",
    "        \n",
    "        y_class_onehotencode = np.array(pd.get_dummies(y_class_groundtruth['Target']))\n",
    "        \n",
    "        for no_of_iterations_to_converge in range(self.total_iterations):\n",
    "            \n",
    "            net = np.dot(X,self.weights) #+ self.bias\n",
    "            net = net.astype('float64')\n",
    "            o_class = (self.softmax(net)) \n",
    "            \n",
    "            #ONES = np.ones((1,N_instances))\n",
    "            #gradient_errorWRTbias = (1/N_instances)*np.dot(ONES,(o_class - y_class_onehotencode))\n",
    "            gradient_errorWRTweights = (1/N_instances)*np.dot(X.T,(o_class - y_class_onehotencode))\n",
    "            #self.bias = self.bias - self.eta_lr*gradient_errorWRTbias\n",
    "            self.weights = self.weights - self.eta_lr*gradient_errorWRTweights\n",
    "        \n",
    "    def prediction(self, X): #for testing data both, we want to predict\n",
    "        N_instances, N_features = X.shape\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "        \n",
    "        net = np.dot(X,self.weights) #+ self.bias\n",
    "        net = net.astype('float64')\n",
    "        y_softmax = self.softmax(net) \n",
    "        \n",
    "        #print(\"y_softmax = \", y_softmax)\n",
    "        #print(\"y_softmax max = \", max(y_softmax))\n",
    "        #print(\"y_softmax min = \", min(y_softmax))\n",
    "        \n",
    "        o_class = np.argmax(y_softmax, axis = 1).reshape(N_instances,1)\n",
    "    \n",
    "        return o_class\n",
    "                    \n",
    "    def softmax(self,net):\n",
    "        b = net.max()\n",
    "        y = np.exp(net - b)\n",
    "        return y / y.sum()\n",
    "        #return np.exp(net)/(np.exp(net).sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_LinearReg_Gradient_Descent(y_class_true,y_class_pred,N_instances):\n",
    "    count_accurate = 0\n",
    "    y_class_true = np.array(y_class_true).reshape(N_instances,1)\n",
    "    y_class_pred = np.array(y_class_pred).reshape(N_instances,1)\n",
    "    \n",
    "   # print(y_class_true[0])\n",
    "    for i in range(N_instances):\n",
    "        if(y_class_true[i] == y_class_pred[i]):\n",
    "            count_accurate = count_accurate + 1\n",
    "    \n",
    "    accuracy = (count_accurate/len(y_class_true))*100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k values from 2 to 10  =  [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "valid_k_values divisible by len(dataset)=  [ 2  3  5  6 10]\n",
      "train_percent =  [ 75 100 120 125 135]\n",
      "test_percent =  [75 50 30 25 15]\n",
      "\n",
      "\n",
      "---------------\n",
      "\n",
      "\n",
      "k = 2 \n",
      "\n",
      "df_train.shape =  (75, 4) df_train_y.shape =  (75, 1)\n",
      "df_test.shape =  (75, 4) df_test_y.shape =  (75, 1)\n",
      "N_classes = 3\n",
      "N_instances_train 75 N_features_train 4 N_instances_test 75 N_features_test 4\n",
      "weights.shape =  (5, 1)\n",
      "Accuracy of model on testing data 68.0 %\n",
      "\n",
      "---------\n",
      "\n",
      "k = 3 \n",
      "\n",
      "df_train.shape =  (100, 4) df_train_y.shape =  (100, 1)\n",
      "df_test.shape =  (50, 4) df_test_y.shape =  (50, 1)\n",
      "N_classes = 3\n",
      "N_instances_train 100 N_features_train 4 N_instances_test 50 N_features_test 4\n",
      "weights.shape =  (5, 1)\n",
      "Accuracy of model on testing data 70.0 %\n",
      "\n",
      "---------\n",
      "\n",
      "k = 5 \n",
      "\n",
      "df_train.shape =  (120, 4) df_train_y.shape =  (120, 1)\n",
      "df_test.shape =  (30, 4) df_test_y.shape =  (30, 1)\n",
      "N_classes = 3\n",
      "N_instances_train 120 N_features_train 4 N_instances_test 30 N_features_test 4\n",
      "weights.shape =  (5, 1)\n",
      "Accuracy of model on testing data 70.0 %\n",
      "\n",
      "---------\n",
      "\n",
      "k = 6 \n",
      "\n",
      "df_train.shape =  (125, 4) df_train_y.shape =  (125, 1)\n",
      "df_test.shape =  (25, 4) df_test_y.shape =  (25, 1)\n",
      "N_classes = 3\n",
      "N_instances_train 125 N_features_train 4 N_instances_test 25 N_features_test 4\n",
      "weights.shape =  (5, 1)\n",
      "Accuracy of model on testing data 64.0 %\n",
      "\n",
      "---------\n",
      "\n",
      "k = 10 \n",
      "\n",
      "df_train.shape =  (135, 4) df_train_y.shape =  (135, 1)\n",
      "df_test.shape =  (15, 4) df_test_y.shape =  (15, 1)\n",
      "N_classes = 3\n",
      "N_instances_train 135 N_features_train 4 N_instances_test 15 N_features_test 4\n",
      "weights.shape =  (5, 1)\n",
      "Accuracy of model on testing data 60.0 %\n",
      "\n",
      "---------\n",
      "\n",
      "max(accuracies) =  70.0 index of max accuracy =  1\n",
      "max accuracy's corresponding k-value =  3\n"
     ]
    }
   ],
   "source": [
    "## K- fold cross validation\n",
    "\n",
    "k_two_to_ten = [i for i in range(2,11)]\n",
    "print(\"k values from 2 to 10  = \",k_two_to_ten)\n",
    " \n",
    "valid_k_values = list(filter(lambda k: len(df)%k == 0, k_two_to_ten)) \n",
    "print(\"valid_k_values divisible by len(dataset)= \",np.array(valid_k_values))\n",
    "\n",
    "valid_k_values_list = []\n",
    "for i in range(len(valid_k_values)):\n",
    "    valid_k_values_list.append(int(valid_k_values[i]))  \n",
    "\n",
    "\n",
    "valid_k_values = np.array(valid_k_values_list)\n",
    "\n",
    "train_percent = ( ((valid_k_values - 1)/valid_k_values) * len(df))\n",
    "test_percent = ( (1/valid_k_values) * len(df))\n",
    "train_percent = train_percent.astype('int32')\n",
    "test_percent = test_percent.astype('int32')\n",
    "print(\"train_percent = \",train_percent)\n",
    "print(\"test_percent = \",test_percent)\n",
    "\n",
    "print(\"\\n\\n---------------\\n\\n\")\n",
    "\n",
    "_ ,features = df.shape\n",
    "features = features - 1\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for i in valid_k_values:\n",
    "    print(\"k =\",i,\"\\n\")\n",
    "    train_percent = ( ((i - 1)/i) * len(df))\n",
    "    test_percent = ( (1/i) * len(df))\n",
    "    train_percent = train_percent.astype('int32')\n",
    "    test_percent = test_percent.astype('int32')\n",
    "\n",
    "    df_train = df[:train_percent,:features].reshape(train_percent, features)\n",
    "    df_train_y = df[:train_percent,-1].reshape(train_percent, 1)\n",
    "\n",
    "    df_test = df[:test_percent,:features].reshape(test_percent,features)\n",
    "    df_test_y = df[:test_percent,-1].reshape(test_percent,1)\n",
    "\n",
    "    print(\"df_train.shape = \",df_train.shape,\"df_train_y.shape = \",df_train_y.shape)\n",
    "    print(\"df_test.shape = \",df_test.shape,\"df_test_y.shape = \",df_test_y.shape)\n",
    "    \n",
    "    classes = np.unique(df_train_y)\n",
    "    N_classes = len(classes)\n",
    "    print(\"N_classes =\",N_classes)\n",
    "    N_instances_train,N_features_train = df_train.shape #N,D\n",
    "    N_instances_test,N_features_test = df_test.shape # N,D ---- we know, N_features_train = N_features_test\n",
    "    print(\"N_instances_train\",N_instances_train,\"N_features_train\",N_features_train,\"N_instances_test\",N_instances_test,\"N_features_test\",N_features_test)\n",
    "\n",
    "\n",
    "    weights = np.zeros((N_features_train + 1, N_classes))\n",
    "    \n",
    "    df_train_y_pd = pd.DataFrame(df_train_y)\n",
    "    df_train_pd = pd.DataFrame(df_train)\n",
    "\n",
    "\n",
    "    df_train_y_pd.columns = ['Target']\n",
    "\n",
    "    df_test_y_pd = pd.DataFrame(df_test_y)\n",
    "    df_test_pd = pd.DataFrame(df_test)\n",
    "\n",
    "\n",
    "    df_test_y_pd.columns = ['Target']\n",
    "    \n",
    "\n",
    "    X_LinearReg_Gradient_Descent =  LinearReg_Gradient_Descent() #Default Learning Rate\n",
    "\n",
    "    X_LinearReg_Gradient_Descent.fit(df_train_pd,df_train_y_pd)\n",
    "    y_class_pred_test = X_LinearReg_Gradient_Descent.prediction(df_test_pd)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    acc = accuracy_LinearReg_Gradient_Descent(df_test_y,y_class_pred_test,len(df_test_y))\n",
    "    Accuracy_Testing = print(\"Accuracy of model on testing data\",acc,\"%\\n\\n---------\\n\")\n",
    "    \n",
    "    #X_LinearReg =  LinearReg() \n",
    "\n",
    "    \n",
    "    #X_LinearReg.fit(df_train.astype(np.float64), df_train_y.astype(np.float64))\n",
    "\n",
    "    \n",
    "    #PRED_CLASS_Test = X_LinearReg.prediction(df_test)\n",
    "    \n",
    "    #print(PRED_CLASS_Test.reshape(test_percent,1).shape)\n",
    "    \n",
    "    #acc = accuracy(PRED_CLASS_Test, df_test_y)\n",
    "\n",
    "    \n",
    "    accuracies.append(acc)\n",
    "\n",
    "max_accuracy = max(accuracies)\n",
    "index_max_accuracy = accuracies.index(max(accuracies))\n",
    "print(\"max(accuracies) = \",max_accuracy,\"index of max accuracy = \" ,index_max_accuracy)\n",
    "print(\"max accuracy's corresponding k-value = \", valid_k_values[index_max_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
